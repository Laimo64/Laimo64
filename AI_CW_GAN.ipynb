{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Laimo64/Laimo64/blob/main/AI_CW_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-kTcjeYesBM",
        "outputId": "8dc61a63-bf11-42f8-88ac-55625de4b75d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1y8OFnIFYC_b_WIexKSog732_L78Pegxa\n",
            "From (redirected): https://drive.google.com/uc?id=1y8OFnIFYC_b_WIexKSog732_L78Pegxa&confirm=t&uuid=3cd60f58-92d0-42e4-b826-fb255f4d2df9\n",
            "To: /content/brain_small.zip\n",
            "100% 119M/119M [00:03<00:00, 37.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/1y8OFnIFYC_b_WIexKSog732_L78Pegxa/view?usp=drive_link\n",
        "!unzip -q brain_small.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=True, delta=0.00005, path=\"checkpoint.pt\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): 容忍驗證損失未改善的次數 (default: 5)\n",
        "            verbose (bool): 是否打印相關資訊 (default: False)\n",
        "            delta (float): 最小改善幅度，只有超過此值才算改善 (default: 0)\n",
        "            path (str): 模型權重保存路徑 (default: \"checkpoint.pt\")\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = float(\"inf\")\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        # 計算當前得分（驗證損失的負值，因為越小越好）\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        \"\"\"保存當前模型權重\"\"\"\n",
        "        if self.verbose:\n",
        "            print(f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...\")\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "def visualize_results(input_image, target_image, predicted_image, epoch, idx):\n",
        "    \"\"\"\n",
        "    視覺化輸入影像、目標影像與預測影像\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # 輸入影像\n",
        "    axes[0].imshow(input_image[0, 0, :, :, input_image.shape[4] // 2].cpu().detach().numpy(), cmap=\"gray\")\n",
        "    axes[0].set_title(\"Input (MR)\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    # 目標影像3\n",
        "    axes[1].imshow(target_image[0, 0, :, :, target_image.shape[4] // 2].cpu().detach().numpy(), cmap=\"gray\")\n",
        "    axes[1].set_title(\"Target (CT)\")\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    # 預測影像\n",
        "    axes[2].imshow(predicted_image[0, 0, :, :, predicted_image.shape[4] // 2].cpu().detach().numpy(), cmap=\"gray\")\n",
        "    axes[2].set_title(\"Prediction (Generated CT)\")\n",
        "    axes[2].axis(\"off\")\n",
        "\n",
        "    plt.suptitle(f\"Epoch {epoch}, Batch {idx}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "zHHe2l-xe0B9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qXybSKLsex5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import Normalize\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "\n",
        "# Data preprocessing and dataset class\n",
        "class MRCTDataset(Dataset):\n",
        "    def __init__(self, data_dir, target_size=(128, 128, 128)):\n",
        "        self.data_dir = data_dir\n",
        "        self.target_size = target_size\n",
        "        self.samples = [\n",
        "            os.path.join(root)\n",
        "            for root, _, files in os.walk(data_dir)\n",
        "            if \"mr.nii.gz\" in files and \"ct.nii.gz\" in files\n",
        "        ]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample_path = self.samples[idx]\n",
        "        mr = nib.load(os.path.join(sample_path, \"mr.nii.gz\")).get_fdata()\n",
        "        ct = nib.load(os.path.join(sample_path, \"ct.nii.gz\")).get_fdata()\n",
        "\n",
        "        mr = self._normalize(mr)\n",
        "        ct = self._normalize(ct)\n",
        "\n",
        "        mr = self._resize_or_pad(mr, self.target_size)\n",
        "        ct = self._resize_or_pad(ct, self.target_size)\n",
        "\n",
        "        mr = torch.tensor(mr, dtype=torch.float32).unsqueeze(0)\n",
        "        ct = torch.tensor(ct, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        return mr, ct\n",
        "\n",
        "    def _normalize(self, image):\n",
        "        return (image - np.mean(image)) / (np.std(image) + 1e-5)\n",
        "\n",
        "    def _resize_or_pad(self, image, target_size):\n",
        "        zoom_factors = [t / s for t, s in zip(target_size, image.shape)]\n",
        "        return zoom(image, zoom_factors, order=1)\n",
        "\n",
        "# Generator and Discriminator Networks\n",
        "class Generator(nn.Module):   # to transform MR to CT using 3D CNN\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv3d(1, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm3d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose3d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm3d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose3d(64, 1, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh()   # 使範圍在[-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class Discriminator(nn.Module):  # to tell whether the input image is the ground truth from the dataset or generated by the generator\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv3d(1, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv3d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm3d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv3d(128, 1, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Sigmoid()       ###########查查為何跟generator用不同\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Training Loop\n",
        "def train_gan(data_loader, generator, discriminator, g_optimizer, d_optimizer, criterion, epochs=10, device=\"cuda\"):\n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      for i, (mr, ct) in enumerate(data_loader):\n",
        "          mr, ct = mr.to(device), ct.to(device)\n",
        "\n",
        "          # Train Discriminator\n",
        "          real_output = discriminator(ct)\n",
        "          fake_ct = generator(mr)\n",
        "          fake_output = discriminator(fake_ct.detach())\n",
        "\n",
        "          d_loss_real = criterion(real_output, torch.ones_like(real_output))\n",
        "          d_loss_fake = criterion(fake_output, torch.zeros_like(fake_output))\n",
        "          d_loss = (d_loss_real + d_loss_fake) / 2\n",
        "\n",
        "          d_optimizer.zero_grad()\n",
        "          d_loss.backward()\n",
        "          d_optimizer.step()\n",
        "\n",
        "          # Train Generator\n",
        "          fake_output = discriminator(fake_ct)\n",
        "          g_loss = criterion(fake_output, torch.ones_like(fake_output))\n",
        "\n",
        "          g_optimizer.zero_grad()\n",
        "          g_loss.backward()\n",
        "          g_optimizer.step()\n",
        "\n",
        "          if i % 10 == 0:\n",
        "              print(f\"Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(data_loader)}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
        "      visualize_results(mr, ct, fake_output, epoch, idx=1)\n",
        "\n",
        "# Main Script\n",
        "if __name__ == \"__main__\":\n",
        "    data_dir = \"/content/small\"\n",
        "    dataset = MRCTDataset(data_dir)\n",
        "    data_loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "    generator = Generator()\n",
        "    discriminator = Discriminator()\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "    g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n",
        "    d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "\n",
        "    train_gan(data_loader, generator, discriminator, g_optimizer, d_optimizer, criterion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "12V2y3jXevHy",
        "outputId": "592470fb-6b82-4f73-9873-54535e2f55f0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 116)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m116\u001b[0m\n\u001b[0;31m    visualize_results(mr, ct, output, epoch, idx=1)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ULy3fJ56fad5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}